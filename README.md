#### This Project was Developed as part of the Doctoral Dissertation at the University of Urbino, Italy.
# HCEvaluations4UFCE
## Human-centred Evaluations of User Feedback-based Counterfactual Explanations (UFCE)

Welcome to the GitHub repository for HCEvaluations4UFCE, this repository presents the solutions to conduct human-centered evaluations of counterfactual explainer methods.

#### Overview

In the context of Human-centred XAI, an interactive web-based game framework is designed calling it Alien Nutri-Solver. This game framework encompasses a virtual domain-agnostic setting including combinatorial tasks. The tasks are solved by the help of counterfactual explanations, providing an opportunity to analyze the task performance of users, hence, paving the way to assess the goodness of explanations. A post-game survey is integrated to record the user responses on the Likert scale about the understanding, Satisfaction, Actionability, Confidence, and Trust in the provided explanations.

### Key Objectives

This research mainly focuses on:

1. **Understanding Human Comprehension:** Explore how human learners comprehend AI models using XAI tools.
2. **Satisfaction:** Evaluate the satisfaction level of the user on the counterfactual XAI tool.
3. **Trust:** Evaluate the trust of users in the provided explanations by the counterfactual XAI tool.

### HCEvaluations4UFCE in Action

HCEvaluations4UFCE is demonstrated through a game-inspired virtual use case. In this scenario, learners engage in combinatorial problem-solving tasks. The goal is to enhance problem-solving skills and deepen understanding of complex concepts.

### Further Reading

We appreciate your interest in HCEvaluations4UFCE and invite you to explore, contribute, and provide feedback. Together, let's advance the frontiers of human-centered Explainable AI!

For further reading about this project and related publications please visit:
[User feedback-based Counterfactual Explanations()].
[Toward enriched Cognitive Learning with XAI](https://arxiv.org/abs/2312.12290).

#### Our other related works:
- [Introducing User Feedback-Based Counterfactual Explanations (UFCE)](https://link.springer.com/article/10.1007/s44196-024-00508-6)
- 
- [FCE: Feedback Based Counterfactual Explanations for Explainable AI](https://ieeexplore.ieee.org/document/9819899)
  
- [Investigating Human-Centered Perspectives in Explainable Artificial Intelligence](https://ceur-ws.org/Vol-3518/paper4.pdf)
  
- [Towards Human Cognition Level-based Experiment Design for Counterfactual Explanations](https://ieeexplore.ieee.org/abstract/document/9994203)
  
- [How to Build Self-Explaining Fuzzy Systems: From Interpretability to Explainability [AI-eXplained]](https://ieeexplore.ieee.org/document/10384509/references#references)



### License

This work is licensed under a
[Creative Commons Attribution 4.0 International License][cc-by].

[![CC BY 4.0][cc-by-image]][cc-by]

[cc-by]: http://creativecommons.org/licenses/by/4.0/
[cc-by-image]: https://i.creativecommons.org/l/by/4.0/88x31.png
[cc-by-shield]: https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg
